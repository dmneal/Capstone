{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset and extracting TF-IDF features...\n",
      "done in 2.052s.\n",
      "Fitting the NMF model with n_samples=2000 and n_features=1000...\n",
      "done in 4.176s.\n",
      "Topic #0:\n",
      "people think did time law government israel rights say case said make state true evidence don mr point gun let\n",
      "()\n",
      "Topic #1:\n",
      "thanks know does mail advance hi info interested anybody email looking help appreciated card information list send post need video\n",
      "()\n",
      "Topic #2:\n",
      "game team year games win play season players nhl toronto runs division flyers think goal hockey player won defense teams\n",
      "()\n",
      "Topic #3:\n",
      "windows file dos using program use files window problem help os application running drivers version ms screen ftp available code\n",
      "()\n",
      "Topic #4:\n",
      "edu soon com send university internet ftp mail mit information article pub cc mac hope email address contact blood program\n",
      "()\n",
      "Topic #5:\n",
      "key chip clipper keys encryption government use public secure phone enforcement data nsa law doesn communications going security used encrypted\n",
      "()\n",
      "Topic #6:\n",
      "car new 00 10 bike price space cars sale power year engine good condition cost used years miles 12 tires\n",
      "()\n",
      "Topic #7:\n",
      "drive drives hard disk card software floppy mac pc apple computer power scsi controller memory problem monitor board mb video\n",
      "()\n",
      "Topic #8:\n",
      "just like don ve got ll know really sure way good look right thing thought want doesn isn use didn\n",
      "()\n",
      "Topic #9:\n",
      "god jesus bible faith does christian christians christ believe life heaven sin lord church mary religion love human good belief\n",
      "()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devin/anaconda/lib/python2.7/site-packages/sklearn/decomposition/nmf.py:532: UserWarning: Iteration limit reached during fit. Solving for W exactly.\n",
      "  warnings.warn(\"Iteration limit reached during fit. Solving for W exactly.\")\n"
     ]
    }
   ],
   "source": [
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "#from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "t0 = time()\n",
    "print(\"Loading dataset and extracting TF-IDF features...\")\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n",
    "                             stop_words='english')\n",
    "tfidf = vectorizer.fit_transform(dataset.data[:n_samples])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import psycopg2\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "ubuntu=True\n",
    "\n",
    "con = None\n",
    "\n",
    "if ubuntu:\n",
    "    con = psycopg2.connect(database='mountainproject', password='kepler31', user='devin', port=5432, host='/var/run/postgresql/')\n",
    "else:\n",
    "    con = psycopg2.connect(database='mountainproject', user='User')\n",
    "cur = con.cursor()\n",
    "con.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>climb_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222</td>\n",
       "      <td>This is the most scary climb EVAH!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105908771</td>\n",
       "      <td>I like this route.  Nice Rumney crimping, stra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105908771</td>\n",
       "      <td>Are you supposed to move out left to the arete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105908771</td>\n",
       "      <td>no quick clips anymore, bring yer ATC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105908771</td>\n",
       "      <td>The anchors are just two glue-ins.  No links. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    climb_id                                            comment\n",
       "0        222                This is the most scary climb EVAH!!\n",
       "1  105908771  I like this route.  Nice Rumney crimping, stra...\n",
       "2  105908771  Are you supposed to move out left to the arete...\n",
       "3  105908771              no quick clips anymore, bring yer ATC\n",
       "4  105908771  The anchors are just two glue-ins.  No links. ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q= '''\n",
    "    SELECT climb_id, comment\n",
    "    FROM comments;\n",
    "    '''\n",
    "cur.execute(q)\n",
    "df = pd.DataFrame(cur.fetchall())\n",
    "df.columns = ['climb_id', 'comment']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_collect = df.groupby(df.climb_id).apply(lambda x: x.sum()).reset_index(drop=True)\n",
    "df_collect = df.groupby(df.climb_id).apply(sum).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>climb_id</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222</td>\n",
       "      <td>This is the most scary climb EVAH!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>422858852</td>\n",
       "      <td>Not a scary lead. Good fun climbing with lots ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317144148</td>\n",
       "      <td>This is a great climb. Good warm up or last cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>740003033</td>\n",
       "      <td>I like this route... the clipping stances are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317144175</td>\n",
       "      <td>This route is far from being a classic in my b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    climb_id                                            comment\n",
       "0        222                This is the most scary climb EVAH!!\n",
       "1  422858852  Not a scary lead. Good fun climbing with lots ...\n",
       "2  317144148  This is a great climb. Good warm up or last cl...\n",
       "3  740003033  I like this route... the clipping stances are ...\n",
       "4  317144175  This route is far from being a classic in my b..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group = df.groupby(df.climb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "(349,)\n",
      "like just href did http style amp route com class\n",
      "()\n",
      "Topic #1:\n",
      "(349,)\n",
      "really climbing right moves crack crux great good climb fun\n",
      "()\n",
      "Topic #2:\n",
      "(349,)\n",
      "traverse anchor p2 ledge crack rap pitches belay rope second\n",
      "()\n",
      "Topic #3:\n",
      "(349,)\n",
      "clipping right replaced left second route anchors clip anchor bolts\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 4\n",
    "n_top_words = 10\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.05, max_features=n_features,\n",
    "                             stop_words='english')\n",
    "test_tfidf = vectorizer.fit_transform(df_collect.comment)\n",
    "\n",
    "nmf = NMF(n_components=n_topics, random_state=1).fit(test_tfidf)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "word_lists = []\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"Topic #%d:\" % topic_idx)\n",
    "    print topic.argsort().shape\n",
    "    word_lists += [[feature_names[i]\n",
    "                    for i in topic.argsort()[-n_top_words - 1:-1]]]\n",
    "    \n",
    "    print(\" \".join(word_lists[topic_idx]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x349 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = vectorizer.transform(['hey, how does this work this climbing crack rap pitches'])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "d = collections.defaultdict(int)\n",
    "for topic in word_lists:\n",
    "    for word in topic:\n",
    "        d[word] += 1\n",
    "\n",
    "\n",
    "\n",
    "unique_words = []\n",
    "for i, word_list in enumerate(word_lists):\n",
    "    words = []\n",
    "    for word in word_list:\n",
    "        if d[word]<2:\n",
    "            words += [word]\n",
    "    unique_words += [words]\n",
    "for topic in unique_words:\n",
    "    print \" \".join(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.stop_words_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Brainstorming\n",
    "Logistic regression:\n",
    "star guessing based on observed features.\n",
    "Which observed features mean more stars.\n",
    "\n",
    "\n",
    "recommend based on past ticks, ratings, and star inputs\n",
    "\n",
    "Additional recommenders:\n",
    "popularity for people looking for popular or non-popular routes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
