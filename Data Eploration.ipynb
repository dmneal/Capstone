{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import psycopg2\n",
    "import pickle\n",
    "\n",
    "ubuntu=True\n",
    "\n",
    "con = None\n",
    "\n",
    "if ubuntu:\n",
    "    con = psycopg2.connect(database='mountainproject', password='kepler31', user='devin', port=5432, host='/var/run/postgresql/')\n",
    "else:\n",
    "    con = psycopg2.connect(database='mountainproject', user='User')\n",
    "cur = con.cursor()\n",
    "con.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ubuntu=True\n",
    "\n",
    "con = None\n",
    "\n",
    "if ubuntu:\n",
    "    con = psycopg2.connect(database='mountainproject', password='kepler31', user='devin', port=5432, host='/var/run/postgresql/')\n",
    "else:\n",
    "    con = psycopg2.connect(database='mountainproject', user='User')\n",
    "cur = con.cursor()\n",
    "con.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_user_id_gte(table='stars', n=5):\n",
    "    #user_ids from users greater than or equal to n reviews\n",
    "    user_id_gte= '''\n",
    "        SELECT user_id\n",
    "        FROM {}\n",
    "        GROUP BY user_id\n",
    "        HAVING COUNT(user_id) >= %s;\n",
    "        '''.format(table)\n",
    "    cur.execute(user_id_gte, (n,) )\n",
    "    tup_list = cur.fetchall()\n",
    "    #return tup_list\n",
    "    return [tup[0] for tup in tup_list]\n",
    "#user_id_list = get_user_id_gte('stars', 5), len(user_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_climb_id_from_user_id_gte(id_tuple, n, table='stars'):\n",
    "    climb_ids = '''\n",
    "        SELECT climb_id\n",
    "        FROM {}\n",
    "        WHERE user_id IN %s\n",
    "        GROUP BY climb_id\n",
    "        HAVING COUNT(climb_id) >= %s;\n",
    "    '''.format(table)\n",
    "    cur.execute(climb_ids, (id_tuple, n) )\n",
    "    return [tup[0] for tup in cur.fetchall()]\n",
    "#climb_id_list = get_climb_id_from_user_id_gte(tuple(user_id_list), 5), len(climb_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user_id_from_climb_id_gte(id_tuple, n, table='stars'):\n",
    "    #Get user ids with at least n reviews in the climb id tuple\n",
    "    user_ids_sql = '''\n",
    "        SELECT user_id\n",
    "        FROM {}\n",
    "        WHERE climb_id IN %s\n",
    "        GROUP BY user_id\n",
    "        HAVING COUNT(user_id) >= %s;\n",
    "    '''.format(table)\n",
    "    cur.execute(user_ids_sql, (id_tuple, n) )\n",
    "    return [tup[0] for tup in cur.fetchall()]\n",
    "#user_id_list2 = get_user_id_from_climb_id_gte(tuple(climb_id_list), 5), len(user_id_list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_climb_user_ids(table='stars', n=5):\n",
    "    climb_id_old = [0]\n",
    "    climb_id_new = [-2]\n",
    "    user_id_old = [0]\n",
    "    user_id_new = [-2] \n",
    "    user_id_new = get_user_id_gte(table=table, n=n)\n",
    "    while (set(user_id_old) != set(user_id_new)) and \\\n",
    "            (set(climb_id_old) != set(climb_id_new)):\n",
    "        print \"climb list:\", len(climb_id_new)\n",
    "        print \"user list:\", len(user_id_new)\n",
    "        climb_id_old = climb_id_new\n",
    "        climb_id_new = get_climb_id_from_user_id_gte(tuple(user_id_new), \n",
    "                                                     n,\n",
    "                                                     table=table)\n",
    "        user_id_old = user_id_new\n",
    "        user_id_new = get_user_id_from_climb_id_gte(tuple(climb_id_new),\n",
    "                                                    n,\n",
    "                                                    table=table)\n",
    "        \n",
    "    return user_id_new, climb_id_new\n",
    "\n",
    "#(user_id_list, climb_id_list) = find_climb_user_ids(table='stars', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_id_list(id_list, name):\n",
    "    # Save id list for future use\n",
    "    with open('id_list_'+name+'.p','w') as f:\n",
    "        pickle.dump(id_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climb list: 1\n",
      "user list: 7592\n",
      "climb list: 13694\n",
      "user list: 7565\n",
      "climb list: 13678\n",
      "user list: 7562\n",
      "climb list: 13676\n",
      "user list: 7561\n"
     ]
    }
   ],
   "source": [
    "(user_id_list, climb_id_list) = find_climb_user_ids(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_id_list(climb_id_list, 'climb_star5')\n",
    "pickle_id_list(user_id_list, 'user_star5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climb list: 1\n",
      "user list: 2558\n",
      "climb list: 2508\n",
      "user list: 1555\n",
      "climb list: 2042\n",
      "user list: 1415\n",
      "climb list: 1931\n",
      "user list: 1367\n",
      "climb list: 1897\n",
      "user list: 1352\n",
      "climb list: 1884\n",
      "user list: 1350\n",
      "climb list: 1879\n",
      "user list: 1344\n",
      "climb list: 1871\n",
      "user list: 1337\n",
      "climb list: 1864\n",
      "user list: 1331\n",
      "climb list: 1860\n",
      "user list: 1329\n",
      "climb list: 1857\n",
      "user list: 1327\n",
      "climb list: 1854\n",
      "user list: 1326\n"
     ]
    }
   ],
   "source": [
    "(user_id_list_sub, climb_id_list_sub) = find_climb_user_ids(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_id_list(climb_id_list_sub, 'climb_star30')\n",
    "pickle_id_list(user_id_list_sub, 'user_star30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climb list: 1\n",
      "user list: 2255\n",
      "climb list: 1940\n",
      "user list: 1190\n",
      "climb list: 1423\n",
      "user list: 948\n",
      "climb list: 1201\n",
      "user list: 839\n",
      "climb list: 1082\n",
      "user list: 773\n",
      "climb list: 1016\n",
      "user list: 740\n",
      "climb list: 983\n",
      "user list: 724\n",
      "climb list: 973\n",
      "user list: 718\n",
      "climb list: 964\n",
      "user list: 716\n",
      "climb list: 959\n",
      "user list: 712\n",
      "climb list: 951\n",
      "user list: 706\n",
      "climb list: 944\n",
      "user list: 702\n",
      "climb list: 942\n",
      "user list: 701\n",
      "climb list: 940\n",
      "user list: 700\n"
     ]
    }
   ],
   "source": [
    "(user_id_list_sub, climb_id_list_sub) = find_climb_user_ids(n=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_id_list(climb_id_list_sub, 'climb_star35')\n",
    "pickle_id_list(user_id_list_sub, 'user_star35')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Rebels: Select Data Where User is different from consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rebels table dropped\n",
      "rebels table created\n"
     ]
    }
   ],
   "source": [
    "def reset_rebels(cur, con):\n",
    "    print \"You don't want to do this.\"\n",
    "    return\n",
    "    try:\n",
    "        cur.execute(\"DROP TABLE rebels\")\n",
    "        print 'rebels table dropped'\n",
    "    except:\n",
    "        print 'didnt drop'\n",
    "    try:\n",
    "        cur.execute('CREATE TABLE rebels(user_id INTEGER, \\\n",
    "                                       climb_id INT,\\\n",
    "                                       user_stars INT)')\n",
    "        \n",
    "\n",
    "        print 'rebels table created'\n",
    "        \n",
    "    except:\n",
    "        print 'didnt create'\n",
    "        \n",
    "    q = '''\n",
    "    SELECT user_id,\n",
    "           stars.climb_id,\n",
    "           user_stars\n",
    "    FROM stars\n",
    "    JOIN tb_climb\n",
    "    ON tb_climb.climb_id=stars.climb_id\n",
    "    WHERE user_stars > (1.75+stars)\n",
    "    OR user_stars < (0.25 + stars)\n",
    "    ;\n",
    "    '''\n",
    "    cur.execute(q)\n",
    "    \n",
    "    for val in cur.fetchall():\n",
    "        cur.execute(\"INSERT INTO rebels VALUES\"+str(val)\n",
    "                    )     \n",
    "\n",
    "    con.commit()\n",
    "reset_rebels(cur, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climb list: 1\n",
      "user list: 3530\n",
      "climb list: 3896\n",
      "user list: 2957\n",
      "climb list: 3686\n",
      "user list: 2913\n"
     ]
    }
   ],
   "source": [
    "(user_id_list, climb_id_list) = find_climb_user_ids(n=5, table='rebels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_id_list(climb_id_list, 'climb_rebel5')\n",
    "pickle_id_list(user_id_list, 'user_rebel5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(user_id_list, climb_id_list) = find_climb_user_ids(n=10, table='rebels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_id_list(climb_id_list, 'climb_rebel10')\n",
    "pickle_id_list(user_id_list, 'user_rebel10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Generate Sparse Matrix for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_string = 'star5' #'star35'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_ids_from_pickle(pickle_string):\n",
    "    with open('id_list_climb_'+pickle_string+'.p','r') as f:\n",
    "            climb_ids = pickle.load(f)\n",
    "    print '# of climb ids:', len(climb_ids)\n",
    "\n",
    "    with open('id_list_user_'+pickle_string+'.p','r') as f:\n",
    "            user_ids = pickle.load(f)\n",
    "    print '# of user_ids:', len(user_ids)\n",
    "    return climb_ids, user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of climb ids: 13675\n",
      "# of user_ids: 7561\n"
     ]
    }
   ],
   "source": [
    "climb_ids, user_ids = load_ids_from_pickle(pickle_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_set = set(user_ids)\n",
    "climb_set = set(climb_ids)\n",
    "climb_tuple = tuple(climb_ids)\n",
    "\n",
    "#Remove Orphaned ID number.  Orphaned has many orphaned data points\n",
    "if 105990845 in user_ids: user_ids.remove(105990845)\n",
    "\n",
    "climb_dict = {}\n",
    "for i, el in enumerate(climb_tuple):\n",
    "    climb_dict[el]=i\n",
    "\n",
    "data = []\n",
    "row = []\n",
    "col = []\n",
    "data_dict = {}\n",
    "user_ids_csv = []\n",
    "climb_ids_csv = []\n",
    "table = 'stars'\n",
    "for i, user in enumerate(user_ids):\n",
    "    #print user\n",
    "    q = '''\n",
    "    SELECT user_stars, climb_id\n",
    "    FROM {}\n",
    "    WHERE user_id = %s\n",
    "    AND climb_id IN %s\n",
    "    '''.format(table)\n",
    "    cur.execute(q, (user, climb_tuple) )\n",
    "    for el in cur.fetchall():\n",
    "        data += [el[0]]\n",
    "        \n",
    "        user_ids_csv += [user]\n",
    "        row += [i]\n",
    "        \n",
    "        climb_ids_csv += [el[1]]        \n",
    "        col += [climb_dict[el[1]]]\n",
    "        \n",
    "        data_dict[(i,climb_dict[el[1]])] = el[0]\n",
    "    \n",
    "sp_mat_input = (data,(row,col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write to csv\n",
    "df = pd.DataFrame({'User':user_ids_csv,\n",
    "                   'Climb':climb_ids_csv,\n",
    "                   'rating':data})\n",
    "df.to_csv(pickle_string+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Make demeaned values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_string = 'star35' #'star35'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_ids_from_pickle(pickle_string):\n",
    "    with open('id_list_climb_'+pickle_string+'.p','r') as f:\n",
    "            climb_ids = pickle.load(f)\n",
    "    print '# of climb ids:', len(climb_ids)\n",
    "\n",
    "    with open('id_list_user_'+pickle_string+'.p','r') as f:\n",
    "            user_ids = pickle.load(f)\n",
    "    print '# of user_ids:', len(user_ids)\n",
    "    return climb_ids, user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of climb ids: 940\n",
      "# of user_ids: 700\n"
     ]
    }
   ],
   "source": [
    "climb_ids, user_ids = load_ids_from_pickle(pickle_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_set = set(user_ids)\n",
    "climb_set = set(climb_ids)\n",
    "climb_tuple = tuple(climb_ids)\n",
    "\n",
    "#Remove Orphaned ID number.  Orphaned has many orphaned data points\n",
    "if 105990845 in user_ids: user_ids.remove(105990845)\n",
    "\n",
    "climb_dict = {}\n",
    "for i, el in enumerate(climb_tuple):\n",
    "    climb_dict[el]=i\n",
    "\n",
    "data = []\n",
    "row = []\n",
    "col = []\n",
    "data_dict = {}\n",
    "user_ids_csv = []\n",
    "climb_ids_csv = []\n",
    "for i, user in enumerate(user_ids):\n",
    "    #print user\n",
    "    q = '''\n",
    "    SELECT stars.user_stars-(1+tb_climb.stars) as stars_dm, stars.climb_id\n",
    "    FROM stars\n",
    "    JOIN tb_climb\n",
    "    ON tb_climb.climb_id = stars.climb_id\n",
    "    WHERE user_id = %s\n",
    "    AND stars.climb_id IN %s\n",
    "    '''\n",
    "    cur.execute(q, (user, climb_tuple) )\n",
    "    for el in cur.fetchall():\n",
    "        data += [el[0]]\n",
    "        \n",
    "        user_ids_csv += [user]\n",
    "        row += [i]\n",
    "        \n",
    "        climb_ids_csv += [el[1]]        \n",
    "        col += [climb_dict[el[1]]]\n",
    "        \n",
    "        data_dict[(i,climb_dict[el[1]])] = el[0]\n",
    "    \n",
    "sp_mat_input = (data,(row,col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write to csv\n",
    "df = pd.DataFrame({'User':user_ids_csv,\n",
    "                   'Climb':climb_ids_csv,\n",
    "                   'rating':data})\n",
    "df.to_csv(pickle_string+'_dm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Climb</th>\n",
       "      <th>User</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105840361</td>\n",
       "      <td>11228</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105840692</td>\n",
       "      <td>11228</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105862944</td>\n",
       "      <td>11228</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105898680</td>\n",
       "      <td>11228</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105923367</td>\n",
       "      <td>11228</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Climb   User  rating\n",
       "0  105840361  11228    -0.3\n",
       "1  105840692  11228     0.3\n",
       "2  105862944  11228     0.1\n",
       "3  105898680  11228    -1.1\n",
       "4  105923367  11228     0.6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Generate climb observed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = '''\n",
    "    SELECT DISTINCT climb_id, yds, yds_consensus, stars, star_votes, location, type_text\n",
    "    FROM tb_climb\n",
    "    WHERE climb_id IN\n",
    "'''\n",
    "cur.execute(q, (climb_tuple,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105741011</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>164</td>\n",
       "      <td>Idaho,City of Rocks,Breadloaves,Bloody Fingers...</td>\n",
       "      <td>Trad, 1 pitch, 110'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105822918</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>102</td>\n",
       "      <td>Utah,Wasatch Range,Little Cottonwood Canyon,Li...</td>\n",
       "      <td>Trad, 1 pitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105721840</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>80</td>\n",
       "      <td>California,Joshua Tree National Park,Wonderlan...</td>\n",
       "      <td>Trad, 1 pitch, 160'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105858078</td>\n",
       "      <td>5.10c</td>\n",
       "      <td>5.10c</td>\n",
       "      <td>3.2</td>\n",
       "      <td>57</td>\n",
       "      <td>International,North America,Canada,British Col...</td>\n",
       "      <td>Sport, 70'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105732260</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>154</td>\n",
       "      <td>Nevada,Red Rock,Juniper Canyon,Ginger Buttress</td>\n",
       "      <td>Trad, 7 pitches, 900',  Grade III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1      2    3    4  \\\n",
       "0  105741011    5.7    5.7  2.8  164   \n",
       "1  105822918    5.7    5.7  3.1  102   \n",
       "2  105721840    5.9    5.9  2.8   80   \n",
       "3  105858078  5.10c  5.10c  3.2   57   \n",
       "4  105732260    5.9    5.9  3.1  154   \n",
       "\n",
       "                                                   5  \\\n",
       "0  Idaho,City of Rocks,Breadloaves,Bloody Fingers...   \n",
       "1  Utah,Wasatch Range,Little Cottonwood Canyon,Li...   \n",
       "2  California,Joshua Tree National Park,Wonderlan...   \n",
       "3  International,North America,Canada,British Col...   \n",
       "4     Nevada,Red Rock,Juniper Canyon,Ginger Buttress   \n",
       "\n",
       "                                   6  \n",
       "0                Trad, 1 pitch, 110'  \n",
       "1                      Trad, 1 pitch  \n",
       "2                Trad, 1 pitch, 160'  \n",
       "3                         Sport, 70'  \n",
       "4  Trad, 7 pitches, 900',  Grade III  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cur.fetchall())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mapping YDS to South Africa Ewbank because it is purely numeric\n",
    "rating_map={'4th': 2,\n",
    "            '5th': 3.5,\n",
    "            '5.0': 3.5,\n",
    "            '5.1': 5.5,\n",
    "            '5.2': 7.5,\n",
    "            '5.3': 8.5,\n",
    "            '5.4': 10.5,\n",
    "            '5.5': 11.5,\n",
    "            '5.6': 13,\n",
    "            '5.7': 14.5,\n",
    "            '5.7+': 15,\n",
    "            '5.8-': 15.5,\n",
    "            '5.8': 16,\n",
    "            '5.8+': 16.5,\n",
    "            '5.9-': 17,\n",
    "            '5.9': 17.5,\n",
    "            '5.9+': 18,\n",
    "            '5.10': 20,\n",
    "            '5.10+': 21,\n",
    "            '5.10-': 19.5,\n",
    "            '5.10a': 19,\n",
    "            '5.10a/b': 19.5,\n",
    "            '5.10b': 20,\n",
    "            '5.10b/c': 20.5,\n",
    "            '5.10c': 21,\n",
    "            '5.10c/d': 21.5,\n",
    "            '5.10d': 22,\n",
    "            '5.11': 23.5,\n",
    "            '5.11+': 24.5,\n",
    "            '5.11-': 23,\n",
    "            '5.11a': 22.5,\n",
    "            '5.11a/b':22.75,\n",
    "            '5.11b': 23,\n",
    "            '5.11b/c': 23.5,\n",
    "            '5.11c': 24,\n",
    "            '5.11c/d': 24.5,\n",
    "            '5.11d': 25,\n",
    "            '5.12': 27.5,\n",
    "            '5.12+': 28.5,\n",
    "            '5.12-': 26.5,\n",
    "            '5.12a': 26,\n",
    "            '5.12a/b': 26.5,\n",
    "            '5.12b': 27,\n",
    "            '5.12b/c': 27.5,\n",
    "            '5.12c': 28,\n",
    "            '5.12c/d': 28.5,\n",
    "            '5.12d': 29,\n",
    "            '5.13': 31.5,\n",
    "            '5.13+': 32.5,\n",
    "            '5.13-': 30.5,\n",
    "            '5.13a': 30,\n",
    "            '5.13a/b': 30.5,\n",
    "            '5.13b': 31,\n",
    "            '5.13b/c': 31.5,\n",
    "            '5.13c': 32,\n",
    "            '5.13c/d': 32.5,\n",
    "            '5.13d': 33,\n",
    "            '5.14-': 34.5,\n",
    "            '5.14a': 34,\n",
    "            '5.14a/b': 34.5,\n",
    "            '5.14b': 35,\n",
    "            '5.14c': 36,\n",
    "            '5.14d': 37,\n",
    "            '5.15a': 38}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr = '''\n",
    "    select distinct yds_consensus\n",
    "    from tb_climb\n",
    "    '''\n",
    "cur.execute(qr)\n",
    "yds_unique = sorted([yds[0] for yds in cur.fetchall()])\n",
    "set(yds_unique) - set(rating_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Climb</th>\n",
       "      <th>location</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_dif</th>\n",
       "      <th>star_votes</th>\n",
       "      <th>stars</th>\n",
       "      <th>sub_location</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105741011</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>3.8</td>\n",
       "      <td>City of Rocks</td>\n",
       "      <td>Trad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105822918</td>\n",
       "      <td>Utah</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Wasatch Range</td>\n",
       "      <td>Trad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105721840</td>\n",
       "      <td>California</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Joshua Tree National Park</td>\n",
       "      <td>Trad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105858078</td>\n",
       "      <td>International</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>4.2</td>\n",
       "      <td>North America</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105732260</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Red Rock</td>\n",
       "      <td>Trad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Climb       location  rating  rating_dif  star_votes  stars  \\\n",
       "0  105741011          Idaho    14.5           0         164    3.8   \n",
       "1  105822918           Utah    14.5           0         102    4.1   \n",
       "2  105721840     California    17.5           0          80    3.8   \n",
       "3  105858078  International    21.0           0          57    4.2   \n",
       "4  105732260         Nevada    17.5           0         154    4.1   \n",
       "\n",
       "                sub_location   type  \n",
       "0              City of Rocks   Trad  \n",
       "1              Wasatch Range   Trad  \n",
       "2  Joshua Tree National Park   Trad  \n",
       "3              North America  Sport  \n",
       "4                   Red Rock   Trad  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climb_observed_features = pd.DataFrame({'Climb': df.loc[:,0],\n",
    "                                        'rating': [rating_map[yds] for yds in df.loc[:,1] ],\n",
    "                                        'rating_dif': np.array([rating_map[yds] for yds in df.loc[:,1] ]) -\\\n",
    "                                       np.array([rating_map[yds] for yds in df.loc[:,2]]),\n",
    "                                        'stars': df.loc[:,3]+1,\n",
    "                                        'star_votes': df.loc[:,4],\n",
    "                                        'location': [area.split(',')[0] for area in df.loc[:,5]],\n",
    "                                        'sub_location': [area.split(',')[1] for area in df.loc[:,5]],\n",
    "                                        'type': [typ.split(',')[0] for typ in df.loc[:,6]]\n",
    "                                       })\n",
    "climb_observed_features.to_csv(pickle_string+'_observed_features.csv', index=False)\n",
    "climb_observed_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Scratch Work Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp_mat = sp.coo_matrix(sp_mat_input, shape=(len(user_ids), len(climb_ids)) )\n",
    "\n",
    "row2 = []\n",
    "col2 = []\n",
    "data2 = []\n",
    "for key in data_dict:\n",
    "    data2 += [data_dict[key]]\n",
    "    row2 += [key[0]]\n",
    "    col2 += [key[1]]\n",
    "    \n",
    "sp_mat2 = sp.coo_matrix((data2,(row2,col2)), shape=(len(user_ids), len(climb_ids)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 4, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ..., \n",
       "        [0, 0, 0, ..., 0, 4, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_mat2.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 940)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_mat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for el in sp_mat2.toarray().flatten():\n",
    "    if el >5:\n",
    "        i += 1\n",
    "        #print el\n",
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[rating_map[yds] for yds in df.loc[:,1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Matrix Factorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K=10, steps=5000, alpha=0.0002, beta=0.02, e_input=0.1, P=False, Q=False):\n",
    "    (N, M) = R.shape\n",
    "    if P is False and Q is False:\n",
    "        print N\n",
    "        print M\n",
    "        P = np.random.rand(N,K)\n",
    "        Q = np.random.rand(K,M)\n",
    "        \n",
    "        #P = np.ones((N,K))*np.sqrt(3./K)\n",
    "        #Q = np.ones((K,M))*np.sqrt(3./K)\n",
    "    e = None\n",
    "    for step in xrange(steps):\n",
    "        \n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i,j]>0:\n",
    "                    eij = R[i,j] - np.dot(P[i,:], Q[:,j])\n",
    "                    for k in xrange(K):\n",
    "                        P[i,k]=P[i,k]+alpha*(2*eij*Q[k,j]-beta*P[i,k])\n",
    "                        Q[k,j]=Q[k,j]+alpha*(2*eij*P[i,k]-beta*Q[k,j])\n",
    "        eR = np.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i,j] > 0:\n",
    "                    e=e+pow(R[i,j]-np.dot(P[i,:],Q[:,j]),2)\n",
    "                    for k in xrange(K):\n",
    "                        e=e+(beta/2)*(pow(P[i,k],2)+pow(Q[k,j],2))\n",
    "        if e < e_input:\n",
    "            print 'Reached error limit!'\n",
    "            break\n",
    "    return P, Q, e, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699\n",
      "940\n"
     ]
    }
   ],
   "source": [
    "with open('nP.p','r') as f:\n",
    "    nP = pickle.load(f)\n",
    "with open('nQ.p','r') as f:\n",
    "    nQ = pickle.load(f)\n",
    "        \n",
    "nP, nQ, e, step = matrix_factorization(sp_mat2.todense(), steps = 5000)\n",
    "with open('nP.p','w') as f:\n",
    "    pickle.dump(nP, f)\n",
    "with open('nQ.p','w') as f:\n",
    "    pickle.dump(nQ, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 3.05667909,  3.        ,  3.        , ...,  3.        ,\n",
       "          3.        ,  3.        ],\n",
       "        [ 3.05667909,  3.        ,  3.        , ...,  3.        ,\n",
       "          3.        ,  3.        ],\n",
       "        [ 3.05667909,  3.        ,  3.        , ...,  3.        ,\n",
       "          3.        ,  3.        ],\n",
       "        ..., \n",
       "        [ 3.05667909,  3.        ,  3.        , ...,  3.        ,\n",
       "          3.        ,  3.        ],\n",
       "        [ 3.05667909,  3.        ,  3.        , ...,  3.        ,\n",
       "          3.        ,  3.        ],\n",
       "        [ 3.05667909,  3.        ,  3.        , ...,  3.        ,\n",
       "          3.        ,  3.        ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matrix(nP.dot(nQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1462808305060759"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    with open('monday_ubuntu_P', 'w') as f:\n",
    "        pickle.dump(nP, f)\n",
    "    with open('monday_ubuntu_Q', 'w') as f:\n",
    "        pickle.dump(nQ, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix_factorization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-66cfc8017ce1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m          \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         ])\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mP_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix_factorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0me_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mP_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matrix_factorization' is not defined"
     ]
    }
   ],
   "source": [
    "R = np.array([\n",
    "         [5,3,0,1],\n",
    "         [4,0,0,1],\n",
    "         [1,1,0,5],\n",
    "         [1,0,0,4],\n",
    "         [0,1,5,4],\n",
    "        ])\n",
    "P_test, Q_test, e_test, step_test = matrix_factorization(R)\n",
    "print e_test\n",
    "P_test.dot(Q_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R_data = R.flatten()\n",
    "Rs = sp.coo_matrix(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x4 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 13 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
